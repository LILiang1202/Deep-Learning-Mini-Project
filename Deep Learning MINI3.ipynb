{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN_project_MVA.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "8wFfo05IMkXW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "81326db8-9e81-4848-f2bd-23cd575d03bb"
      },
      "cell_type": "code",
      "source": [
        "! pip install scikit-video"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-video in /usr/local/lib/python3.6/dist-packages (1.1.11)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.14.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from scikit-video) (4.0.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->scikit-video) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R3kwnyC0HK8G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import keras\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "import skvideo.io\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "from keras.models import Sequential,model_from_json\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import sgd\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jReApuCpHK8E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
      ]
    },
    {
      "metadata": {
        "id": "iaAN_yb1HK8M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MiniProject #3: Deep Reinforcement Learning"
      ]
    },
    {
      "metadata": {
        "id": "R1WgNr7-HK8P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
      ]
    },
    {
      "metadata": {
        "id": "i_V-NstJHK8R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Context"
      ]
    },
    {
      "metadata": {
        "id": "8MDwS3F-HK8S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
        "\n",
        "\\begin{equation*}\n",
        "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
        "\\end{equation*}\n",
        "\n",
        "where: \n",
        "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "We note the $Q$-function:\n",
        "\n",
        "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "Thus, the optimal Q function is:\n",
        "\\begin{equation*}\n",
        "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
      ]
    },
    {
      "metadata": {
        "id": "NBw8C25LHK8U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The environment, the agent and the game"
      ]
    },
    {
      "metadata": {
        "id": "XSNFcpL0HK8Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The environment"
      ]
    },
    {
      "metadata": {
        "id": "ziTAHj8OHK8Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
      ]
    },
    {
      "metadata": {
        "id": "hcR8NnmcHK8a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Environment(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def act(self, act):\n",
        "        \"\"\"\n",
        "        One can act on the environment and obtain its reaction:\n",
        "        - the new state\n",
        "        - the reward of the new state\n",
        "        - should we continue the game?\n",
        "\n",
        "        :return: state, reward, game_over\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reinitialize the environment to a random state and returns\n",
        "        the original state\n",
        "\n",
        "        :return: state\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def draw(self):\n",
        "        \"\"\"\n",
        "        Visualize in the console or graphically the current state\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JQ_V3iKAHK8f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
        "\n",
        "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
        "\n",
        "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
        "\n",
        "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
      ]
    },
    {
      "metadata": {
        "id": "XvbiawhtHK8h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The Agent"
      ]
    },
    {
      "metadata": {
        "id": "oVc_0z5kHK8j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
      ]
    },
    {
      "metadata": {
        "id": "-KTwqNwtHK8k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Agent(object):\n",
        "    \n",
        "    def __init__(self, epsilon=0.1, n_action=4):\n",
        "        self.epsilon = epsilon\n",
        "        self.n_action = n_action\n",
        "    \n",
        "    def set_epsilon(self,e):\n",
        "        self.epsilon = e\n",
        "    \n",
        "    def get_epsilon(self):\n",
        "        return self.epsilon\n",
        "        \n",
        "        \n",
        "        \n",
        "    def get_epsilon(self):\n",
        "        return self.epsilon\n",
        "\n",
        "    def act(self,s,train=True):\n",
        "        \"\"\" This function should return the next action to do:\n",
        "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
        "        if train:\n",
        "            if np.random.rand() <= self.epsilon:    #Create an array of the given shape and populate it with random samples from a uniform distribution over [0, 1)\n",
        "                a = np.random.randint(0, self.n_action, size=1)[0]   #Return random integers from low (inclusive) to high (exclusive).\n",
        "            else:\n",
        "                a = self.learned_act(s)\n",
        "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
        "            a = self.learned_act(s)\n",
        "\n",
        "        return a\n",
        "\n",
        "    def learned_act(self,s):\n",
        "        \"\"\" Act via the policy of the agent, from a given state s\n",
        "        it proposes an action a\"\"\"\n",
        "        pass\n",
        "\n",
        "    def reinforce(self, s, n_s, a, r, game_over_):\n",
        "        \"\"\" This function is the core of the learning algorithm. \n",
        "        It takes as an input the current state s_, the next state n_s_\n",
        "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
        "        \n",
        "        Its goal is to learn a policy.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\" This function returns basic stats if applicable: the\n",
        "        loss and/or the model\"\"\"\n",
        "        pass\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\" This function allows to restore a model\"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OmIGQ-9NHK8s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "__Question 1__:\n",
        "Explain the function act. Why is ```epsilon``` essential?"
      ]
    },
    {
      "metadata": {
        "id": "vA73qIeRHK8t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The act function here is to train the agent to find the optimal action that can maximise the reward. There are two choice: exploration and exploitation. Exploration here means gathering more information from the environment, while exploitation means taking action based on the information given. If the agent does not explore, he will always choose a certain one action in the future, even if there is a way better option available. If the agent only applies exploration, all actions will be chosen randomly, so that it is impossible to maximise the reward. Thus, we need a tradeoff between exploration and exploitation.\n",
        "\n",
        "Trading off exploration and exploitation means that  the agent makes the decision at each step of the way; he can either choose to take a random action or choose the trusted action. The probability of taking random action is known as** Epsilon** in this algorithm and **1-Epsilon** as the probability of exploiting the recommended action.\n",
        "\n",
        "The above act function indicates that \n",
        "1. we randomly set a number between 0 and 1, and if this number <= epsilon, the agent will explore, othervise, he will exploit.\n",
        "2. After the agent has explored enought strategies from the enviroment, he will always apply exploitation action with the best reward."
      ]
    },
    {
      "metadata": {
        "id": "NFy0vedWHK8v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "### The Game"
      ]
    },
    {
      "metadata": {
        "id": "UjMeXfFWHK8x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
        "\n",
        "```python\n",
        "\n",
        "epoch = 300\n",
        "env = Environment()\n",
        "agent = Agent()\n",
        "\n",
        "\n",
        "# Number of won games\n",
        "score = 0\n",
        "loss = 0\n",
        "\n",
        "\n",
        "for e in range(epoch):\n",
        "    # At each epoch, we restart to a fresh game and get the initial state\n",
        "    state = env.reset()\n",
        "    # This assumes that the games will end\n",
        "    game_over = False\n",
        "\n",
        "    win = 0\n",
        "    lose = 0\n",
        "    \n",
        "    while not game_over:\n",
        "        # The agent performs an action\n",
        "        action = agent.act(state)\n",
        "\n",
        "        # Apply an action to the environment, get the next state, the reward\n",
        "        # and if the games end\n",
        "        prev_state = state\n",
        "        state, reward, game_over = env.act(action)\n",
        "\n",
        "        # Update the counters\n",
        "        if reward > 0:\n",
        "            win = win + reward\n",
        "        if reward < 0:\n",
        "            lose = lose -reward\n",
        "\n",
        "        # Apply the reinforcement strategy\n",
        "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "    # Save as a mp4\n",
        "    if e % 10 == 0:\n",
        "        env.draw(e)\n",
        "\n",
        "    # Update stats\n",
        "    score += win-lose\n",
        "\n",
        "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "          .format(e, epoch, loss, win, lose, win-lose))\n",
        "    agent.save()\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "m12Za4cIHK8y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# The game, *eat cheese*"
      ]
    },
    {
      "metadata": {
        "id": "Vq0XKoHvHK8z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
        "\n",
        "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
      ]
    },
    {
      "metadata": {
        "id": "ceozG6XmHK85",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Environment(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((\n",
        "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tj8wUfzqVXLh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fk9HNt39HK8_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following elements are important because they correspond to the hyper parameters for this project:"
      ]
    },
    {
      "metadata": {
        "id": "WlumnTCJHK9A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "size = 13\n",
        "T=200\n",
        "temperature=0.3\n",
        "epochs_train=20 # set small when debugging\n",
        "epochs_test=20 # set small when debugging\n",
        "\n",
        "# display videos\n",
        "def display_videos(name):\n",
        "    video = io.open(name, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    return '''<video alt=\"test\" controls>\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tm2ay7DOHK9G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
      ]
    },
    {
      "metadata": {
        "id": "qHJBlyWHHK9I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The use of the array position is to determine where is the rat on the board at a given time. The array is updated for each call of function **act** by setting to zeros all the elements except the position of the rat that is set to 1. \n",
        "\n",
        "The array board defines the board on which the rat moves around. It is a view of  the reward. Each board represents cheese, neutral or poisonous, worthing 0.5, 0 and -1 respectively\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "5o42EzhzHK9K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Random Agent"
      ]
    },
    {
      "metadata": {
        "id": "XiixiBWkHK9L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
      ]
    },
    {
      "metadata": {
        "id": "P0LHqBtFHK9N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RandomAgent(Agent):\n",
        "    def __init__(self):\n",
        "        super(RandomAgent, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        return np.random.randint(0,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cFdQzT0ZHK9X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
      ]
    },
    {
      "metadata": {
        "id": "lSc9GyM7HK9Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test(agent,env,epochs,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "        \n",
        "    for e in range(epochs):\n",
        "        \n",
        "    # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "    # This assumes that the games will end\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "        # The agent performs an action\n",
        "            action = agent.learned_act(state)\n",
        "\n",
        "        # Apply an action to the environment, get the next state, the reward\n",
        "        # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "        # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "        \n",
        "        # Save as a mp4\n",
        "        env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score = score + win-lose\n",
        "\n",
        "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
        "              .format(win, lose, score/(1+e)))\n",
        "    print('Final score: '+str(score/epochs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CHwYO-4pHK9b",
        "colab_type": "code",
        "outputId": "a4fc20ca-22db-45cb-b801-eec26c37999a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        }
      },
      "cell_type": "code",
      "source": [
        "# Initialize the game\n",
        "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
        "\n",
        "# Initialize the agent!\n",
        "agent = RandomAgent()\n",
        "\n",
        "test(agent,env,epochs_test,prefix='random')\n",
        "HTML(display_videos('random0.mp4'))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 4.0/6.0. Average score (-2.0)\n",
            "Win/lose count 4.0/11.0. Average score (-4.5)\n",
            "Win/lose count 2.0/2.0. Average score (-3.0)\n",
            "Win/lose count 3.0/7.0. Average score (-3.25)\n",
            "Win/lose count 2.5/6.0. Average score (-3.3)\n",
            "Win/lose count 8.5/5.0. Average score (-2.1666666666666665)\n",
            "Win/lose count 4.0/9.0. Average score (-2.5714285714285716)\n",
            "Win/lose count 5.5/9.0. Average score (-2.6875)\n",
            "Win/lose count 6.0/6.0. Average score (-2.388888888888889)\n",
            "Win/lose count 4.0/5.0. Average score (-2.25)\n",
            "Win/lose count 6.0/5.0. Average score (-1.9545454545454546)\n",
            "Win/lose count 7.5/11.0. Average score (-2.0833333333333335)\n",
            "Win/lose count 5.0/1.0. Average score (-1.6153846153846154)\n",
            "Win/lose count 3.0/10.0. Average score (-2.0)\n",
            "Win/lose count 4.5/9.0. Average score (-2.1666666666666665)\n",
            "Win/lose count 2.0/4.0. Average score (-2.15625)\n",
            "Win/lose count 4.0/6.0. Average score (-2.1470588235294117)\n",
            "Win/lose count 5.5/5.0. Average score (-2.0)\n",
            "Win/lose count 6.5/4.0. Average score (-1.763157894736842)\n",
            "Win/lose count 6.0/6.0. Average score (-1.675)\n",
            "Final score: -1.675\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "metadata": {
        "id": "lArdcVwdHK9h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "## DQN"
      ]
    },
    {
      "metadata": {
        "id": "ojJ5AO9aHK9i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let us assume here that $T=\\infty$.\n",
        "\n",
        "***\n",
        "__Question 5__ Let $\\pi$ be a policy, show that:\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
        "\\end{equation*}\n",
        "Finally, deduce that a plausible objective is:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "rxp9GVTbHK9k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1. The Q function can be written as:\n",
        "\n",
        "$$\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\; .\n",
        "\\end{equation*}$$\n",
        "\n",
        "     we can rewrite the above equation based on Bellman Equation:\n",
        "\n",
        "$$\\begin{equation*}Q^\\pi(s,a)=E_{(s', a')\\sim p(.|s,a)}[r(s,a) + {\\gamma}\\sum_{t\\leq T}\\gamma^{t}r(s_{t+1},a_{t+1})|s_{0}=s,a_{0}=a] ; \n",
        "\\end{equation*}$$$$\\begin{equation*} Thus, Q^\\pi(s,a)=E_{(s', a')\\sim p(.|s,a)}[r(s,a) + {\\gamma}Q^\\pi(s',a')] \\; .\n",
        "\\end{equation*}$$\n",
        ".\n",
        "\n",
        "\n",
        "\n",
        "2. from the previous proof, we have that :\n",
        "\n",
        "$$\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}$$\n",
        "      \n",
        "\n",
        "$$\\begin{equation*}\n",
        "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\; \n",
        "\\end{equation*}$$$$\\begin{equation*}\n",
        "Q^*(s,a)= \\max_{\\pi} E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')] \\; \n",
        "\\end{equation*}$$$$\\begin{equation*}\n",
        "Q^*(s,a)= E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
        "\\end{equation*}$$\n",
        "\n",
        "(linearity of the maximum)\n",
        "\n",
        "3. Finally, a plausible objective is \n",
        "\n",
        "$$\\begin{equation*}\n",
        "\\mathcal{L}(\\theta) = E_{s' \\sim \\pi^*(.|s,a)}( ( Q^* (s,a,\\theta ) - Q(s,a,\\theta)) ^2) \n",
        "\\end{equation*}$$$$\\begin{equation*}\n",
        "\\mathcal{L}(\\theta) =  E_{s' \\sim \\pi^*(.|s,a)} ( ( r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a', \\theta) - Q(s,a,\\theta)) ^2) \n",
        "\\end{equation*}$$$$\\begin{equation*}\n",
        "\\mathcal{L}(\\theta) = E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}$$"
      ]
    },
    {
      "metadata": {
        "id": "qJe9MnzGHK9l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
        "\n",
        "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
        "\n",
        "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
        "\n",
        "3. Store $(s_t,a_t,s_{t+1})$;\n",
        "\n",
        "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
        "\n",
        "***\n",
        "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
      ]
    },
    {
      "metadata": {
        "id": "rC4vuIwzHK9n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Memory(object):\n",
        "    def __init__(self, max_memory=100):\n",
        "        self.max_memory = max_memory\n",
        "        self.memory = list()\n",
        "\n",
        "    def remember(self, m):\n",
        "        self.memory.append(m)\n",
        "\n",
        "    def random_access(self):\n",
        "      index=np.random.randint(0,len(self.memory))\n",
        "      return self.memory[index]\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zz8FM_MtHK9u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "The pipeline we will use for training is given below:"
      ]
    },
    {
      "metadata": {
        "id": "qbk55inXHK9w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b8Cf-HruHK94",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
      ]
    },
    {
      "metadata": {
        "id": "8td_nflXHK96",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DQN(Agent):\n",
        "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
        "        super(DQN, self).__init__(epsilon = epsilon)\n",
        "\n",
        "        # Discount for Q learning\n",
        "        self.discount = 0.99\n",
        "        \n",
        "        self.grid_size = grid_size\n",
        "        \n",
        "        # number of state\n",
        "        self.n_state = n_state\n",
        "\n",
        "        # Memory\n",
        "        self.memory = Memory(memory_size)\n",
        "        \n",
        "        # Batch size when learning\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        #predict the reward value\n",
        "        act_value = self.model.predict(np.reshape(s, (1, 5, 5, self.n_state)))\n",
        "        return np.argmax(act_value[0])\n",
        "        \n",
        "        #pass\n",
        "\n",
        "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
        "        # Two steps: first memorize the states, second learn from the pool\n",
        "\n",
        "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
        "        \n",
        "        input_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
        "        target_q = np.zeros((self.batch_size, 4))\n",
        "        \n",
        "        for i in range(self.batch_size):\n",
        "            batch=self.memory.random_access()\n",
        "            input_states[i]=batch[0] \n",
        "            game_over_=batch[4] \n",
        "            \n",
        "            if game_over_:\n",
        "                \n",
        "                target_q[i, batch[2]] = batch[3] \n",
        "            else:\n",
        "               \n",
        "                x = np.reshape(batch[1], (1, 5, 5, self.n_state)) \n",
        "                target_q[i, batch[2]] = batch[3] + self.discount * np.amax(self.model.predict(x))\n",
        "                                         \n",
        "        target_q = np.clip(target_q, -3, 3)\n",
        "\n",
        "        l = self.model.train_on_batch(input_states, target_q)\n",
        "\n",
        "\n",
        "        return l\n",
        "\n",
        "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
        "        self.model.save_weights(name_weights, overwrite=True)\n",
        "        with open(name_model, \"w\") as outfile:\n",
        "            json.dump(self.model.to_json(), outfile)\n",
        "            \n",
        "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
        "        with open(name_model, \"r\") as jfile:\n",
        "            model = model_from_json(json.load(jfile))\n",
        "        model.load_weights(name_weights)\n",
        "        model.compile(\"sgd\", \"mse\")\n",
        "        self.model = model\n",
        "\n",
        "            \n",
        "class DQN_FC(DQN):\n",
        "    def __init__(self, *args, lr=0.1,**kwargs):\n",
        "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
        "        \n",
        "        # NN Model\n",
        "        \n",
        "        ####### FILL IN\n",
        "        model = Sequential()\n",
        "        model.add(Reshape((5*5*self.n_state,), input_shape=(5,5,self.n_state)))\n",
        "        model.add(Dense(512, input_dim=50, activation='relu'))\n",
        "        model.add(Dense(218, activation='relu'))\n",
        "        model.add(Dense(4, activation='linear')) \n",
        "        \n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "irJr15jrHK-A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "outputId": "e2021958-abf2-41af-fa18-7b5b1e439fbd"
      },
      "cell_type": "code",
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "train(agent, env, epochs_train, prefix='fc_train')\n",
        "HTML(display_videos('fc_train10.mp4'))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/020 | Loss 0.0036 | Win/lose count 8.0/4.0 (4.0)\n",
            "Epoch 001/020 | Loss 0.0077 | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 002/020 | Loss 0.0197 | Win/lose count 7.5/12.0 (-4.5)\n",
            "Epoch 003/020 | Loss 0.0057 | Win/lose count 5.5/4.0 (1.5)\n",
            "Epoch 004/020 | Loss 0.0107 | Win/lose count 7.0/2.0 (5.0)\n",
            "Epoch 005/020 | Loss 0.0101 | Win/lose count 4.0/2.0 (2.0)\n",
            "Epoch 006/020 | Loss 0.0199 | Win/lose count 6.0/7.0 (-1.0)\n",
            "Epoch 007/020 | Loss 0.0099 | Win/lose count 5.0/4.0 (1.0)\n",
            "Epoch 008/020 | Loss 0.0121 | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 009/020 | Loss 0.0291 | Win/lose count 7.0/4.0 (3.0)\n",
            "Epoch 010/020 | Loss 0.0092 | Win/lose count 5.0/3.0 (2.0)\n",
            "Epoch 011/020 | Loss 0.0048 | Win/lose count 13.5/10.0 (3.5)\n",
            "Epoch 012/020 | Loss 0.0124 | Win/lose count 10.0/5.0 (5.0)\n",
            "Epoch 013/020 | Loss 0.0159 | Win/lose count 7.0/4.0 (3.0)\n",
            "Epoch 014/020 | Loss 0.0102 | Win/lose count 5.0/5.0 (0.0)\n",
            "Epoch 015/020 | Loss 0.0108 | Win/lose count 7.5/4.0 (3.5)\n",
            "Epoch 016/020 | Loss 0.0165 | Win/lose count 9.0/4.0 (5.0)\n",
            "Epoch 017/020 | Loss 0.0088 | Win/lose count 5.5/5.0 (0.5)\n",
            "Epoch 018/020 | Loss 0.0197 | Win/lose count 6.5/4.0 (2.5)\n",
            "Epoch 019/020 | Loss 0.0064 | Win/lose count 2.5/4.0 (-1.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAF65tZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiByMjg1NCBlOWE1OTAzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MToweDExMSBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MCBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD00IHRocmVhZHM9MyBsb29rYWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAMqZYiEADf//vaH+BTZWBP+Wb/9DX/cj9uPrP1xYyEE31qvIejAGS+1H+b/rFFs6Z6UB/fgCJQAc24ZwpHZJ3jjhJSYReqPgUuAn34FNJkU+vl2k1sRHhvyFH3AQPUs9BqH1YpP+tGVa50ZuBULhwT8mg1zUITUZw2JedGALbwWY4I4IQjf94TXEFNcmPwTJrXBzgxWpHyfbXvRznHOiFjBhxPyc7bcQ0ptTvxVKTsENC70WSI6kqIJvGyErcvWrKP+2J+3V2p3VDdQ1dFSpLFaaLVIH66ScuYppR596exnhkCmkt8qRGXJgRBjJIhcvqp80JnZmHM6+RBJAkfxzh0AUq+i/PzDcKZNcbcpuwsXd+Ng/kLuwvetK0AyAY6MA9bMoL2ILS8E7K2Cda10fCZqtjwAO+cQh85ACbR+u9J/h/kSOwLzVWVVMED96jnoYToCQo67F8AgHG0sOfnDbfIlvzAP7j+7JcRiAJ9T2uhkSUpZwUexvxFSdekDwMRPfxhwAigNCPOcuzJcQMOqshgFCyIWms6E/c3z3hMTAp5800HCKEOi6q9NLObyq/xQt54AlXgXGuZjXiDELu2/09nEU4ZZGgMDc/bjaVwIoBLIq7PagP2S/JHWiE7tOV8ykJi5jPZrjKNvTviEAiIMoR+Y7ZndcQahQcRTI8jYC9CRws+1tXecPw2QUXTGNAJJ9NJJX0NqpK7o66TVi8W/AA5K/SoRQVhVRirBFIZHXRQp++dZYz3j5c2le2w3OsiTGLljWQR3L9ST3WkIPKRlgYUf2A1axAWFo/qUSbADyl0OY7VWwhmsLYoIVzhyVLh4xCxx30qKo/CdWMko7o7YSPr8fNqxPqM1kFeAT9GH7WJw+hQwLgrVfS5QKQnX6hYEQd4qALbBb4lU2H7BAYeS7eNbR0RMr8Uo9N+F4+kEsTCY3o3bWmBbMFR+AjFwlb1B4y2Nt3oCyUDb7lG8dYccdeT7HxSkSOs9HsbEgWURspsAcFrnag4hORMykYMXnA7/GaleAqF579/DohqE5/oFyzIMqi0Z1og9+sMC80PF9zgQIPUrm5N3WN4AAC9hAAAAFEGaIWxDf/6nhAARV1rNts+z5ySAAAAAJ0GaRDwhkymEN//+p4QAK17dPMsq2yn4FJaB/ApltHLt7DOtKDsjMQAAABFBnmJqU8K/ACK7Q4C5YzX6nwAAABABnoNqQr8AIrs8cr9YpLXBAAAAGkGahUmoQWiZTAh3//6plgAhCLDdFJnfdq3RAAAAKUGaqUnhClJlMCG//qeEAGT9l9XwKa+oV+BSpbPwKZ2Bjbu29zV8apTBAAAAEEGex0U0TC//ADtfxV2ZI4sAAAAQAZ7mdEK/AFHzRInxZijkEAAAAA8BnuhqQr8AUflYF1/f8EAAAAASQZrrSahBaJlMFPDf/qeEAAEnAAAAEAGfCmpCvwBR43OF0kpMWqgAAAASQZsNSeEKUmUwUsN//qeEAAEnAAAAEAGfLGpCvwBR43OF0kpMWqkAAAASQZsvSeEOiZTBRMN//qeEAAEnAAAAEAGfTmpCvwBR43OF0kpMWqkAAAASQZtRSeEPJlMFPDf//qeEAAEnAAAAEAGfcGpCvwBR43OF0kpMWqgAAAASQZtzSeEPJlMFPDf//qeEAAEnAAAAEAGfkmpCvwBR43OF0kpMWqgAAAASQZuVSeEPJlMFPDf//qeEAAEnAAAAEAGftGpCvwBR43OF0kpMWqkAAAAcQZu5SeEPJlMCGf/+nhACaiHKtwXG+/rRHRswTAAAABBBn9dFETwv/wBflTQ0ulNvAAAADwGf9nRCvwBR4xi4D8tqoQAAABABn/hqQr8AfxmDyYHr26CAAAAAHEGb+kmoQWiZTAhv//6nhADxnGf6rfVQIT+6X+EAAAAYQZobSeEKUmUwIb/+p4QBjggs2vc1F3dAAAAAGEGaPEnhDomUwId//qmWAiRMN0Q5OD5aQQAAABZBmkBJ4Q8mUwId//6plgIB4Y/L2K+BAAAAFEGefkURPC//AWUx40fH69HfFsaAAAAAEAGenXRCvwHefwGSWf1lrYAAAAAQAZ6fakK/Ad8ff3xoavymgQAAABJBmoRJqEFomUwIb//+p4QAAScAAAAQQZ6iRREsL/8BZYlq3WPahwAAABABnsF0Qr8B3n8Bkln9Za2AAAAAEAGew2pCvwHfH398aGr8poEAAAASQZrISahBbJlMCG///qeEAAEnAAAAEEGe5kUVLC//AWWJat1j2ocAAAAQAZ8FdEK/Ad5/AZJZ/WWtgQAAABABnwdqQr8B3x9/fGhq/KaAAAAAGUGbCkmoQWyZTBRMN//+p4QEMUdGpW1sTMAAAAAQAZ8pakK/Ad6y/VHzH4tjQQAAABlBmytJ4QpSZTAhv/6nhAGC8dPpfFCQwo+AAAAAEUGbT0nhDomUwIZ//p4QAAR8AAAAE0GfbUURPC//AI76CKUjpnLFoG8AAAAQAZ+MdEK/AMOApnlfkpswcQAAABABn45qQr8AyILGveaVm1JBAAAAGkGbkEmoQWiZTAhv//6nhADxg8KdZ0+62umAAAAAGEGbsUnhClJlMCG//qeEAY4ILNr3NRd3QAAAABhBm9RJ4Q6JlMCG//6nhAGR8dMf4fVbcasAAAASQZ/yRRE8K/8B3zYHQgsLTG9AAAAAEAGeE2pCvwHesv1R8x+LY0AAAAAaQZoVSahBaJlMCG///qeEAYLx0+l8UJDCj4EAAAARQZo5SeEKUmUwIZ/+nhAABHwAAAATQZ5XRTRML/8AjvoIpSOmcsWgbwAAABABnnZ0Qr8Aw4CmeV+SmzBxAAAAEAGeeGpCvwDIgsa95pWbUkAAAAAaQZp6SahBaJlMCG///qeEAPGDwp1nT7ra6YEAAAAYQZqbSeEKUmUwIb/+p4QBjggs2vc1F3dAAAAAG0GavknhDomUwIb//qeEAZHyOATXr2Z8C3qPgQAAABJBntxFETwr/wHfNgdCCwtMb0EAAAAQAZ79akK/Ad6y/VHzH4tjQAAAABtBmuJJqEFomUwIb//+p4QEMUdGt7B+Epa+JLwAAAARQZ8ARREsL/8BZVXW79gf0jEAAAAPAZ8/dEK/AS60IDJLlJuAAAAAEAGfIWpCvwHfH398aGr8poEAAAAYQZskSahBbJlMFEwz//6eEA9oRu+HbDllAAAAEAGfQ2pCvwHesv1R8x+LY0EAAAAZQZtFSeEKUmUwIb/+p4QBgvHT6XxQkMKPgQAAABhBm2ZJ4Q6JlMCG//6nhADtewevZnwRXR8AAAAaQZuISeEPJlMFETw3//6nhAF/tpaLe6nxMg8AAAAPAZ+nakK/AS7YjyYHr20PAAAAG0Gbq0nhDyZTAhn//p4QDkg45+YJggKZ+XTrgAAAABJBn8lFETwr/wHSH8y3huQcSHkAAAAQAZ/qakK/Ad6F70iY1mWHgAAAABlBm+xJqEFomUwIb//+p4QELjMeSDH5teLKAAAAFkGaDUnhClJlMCG//qeEBDFHMQfvlpEAAAAdQZovSeEOiZTBTRMN//6nhAGR8dPtFGFsxQjjq2kAAAAPAZ5OakK/ATaVulGkPEn3AAAAGUGaUknhDyZTAhv//qeEAO17B/hOC3QkYEAAAAARQZ5wRRE8K/8AyLNzXHveoRsAAAAOAZ6RakK/AMiSGeiK2z8AAAAaQZqTSahBaJlMCHf//qmWAE5+PP37INxT/zAAAAASQZq3SeEKUmUwId/+qZYAAJWAAAAADEGe1UU0TC//AACygQAAABABnvR0Qr8AUOyjvwAfbuPAAAAAEAGe9mpCvwBQ7KO9nj7dx4EAAAASQZr7SahBaJlMCG///qeEAAEnAAAADEGfGUURLC//AACygAAAABABnzh0Qr8AUOyjvwAfbuPBAAAAEAGfOmpCvwBQ7KO9nj7dx4AAAAAbQZs/SahBbJlMCG///qeEAOwcch6tAvdT5G6ZAAAAEEGfXUUVLC//AI7n6DlDpt0AAAAPAZ98dEK/AFHjGLgPy2qgAAAAEAGffmpCvwDDu1HK/tw+kEAAAAATQZthSahBbJlMFEw3//6nhAABJwAAAA8Bn4BqQr8AyILGwOU2pIAAAAASQZuDSeEKUmUwUsM//p4QAAR9AAAADwGfompCvwDIgsaJXPLplQAAABhBm6RJ4Q6JlMCGf/6eEAOv64296b7ra6cAAAAZQZvFSeEPJlMCG//+p4QA9wPCnWdPutrjgQAAACFBm+dJ4Q8mUwURPDf//qeEAa4K1TH8uMXX8/EcAmv4kk8AAAAQAZ4GakK/AUiwjyYHr2z5gQAAABhBmghJ4Q8mUwIb//6nhAGuCtHNgEtI6g4AAAAeQZoqSeEPJlMFETw3//6nhAGh8foE7/lWjwA+Z62YAAAAEAGeSWpCvwE/a+c60MLw70EAAAAcQZpMSeEPJlMFPDv//qmWAMKo6hBmgI+0v61lbAAAABABnmtqQr8BLtohNxn16arYAAAAGEGacEnhDyZTAhv//qeEAYLx0+1hVnCK2QAAABBBno5FETwv/wDcqvG9gih5AAAADwGerXRCvwEutCAyS5SbgQAAABABnq9qQr8BNs0bzTFW0cjAAAAAGkGasUmoQWiZTAh3//6plgB8x0/KaMfrST/AAAAAGEGa1EnhClJlMCHf/qmWAH19peNplgDbgQAAABJBnvJFNEwr/wE/wdd3f0isesAAAAAQAZ8TakK/AT9r5zrQwvDvQAAAABJBmxhJqEFomUwIb//+p4QAAScAAAATQZ82RREsL/8A3HrljNuJ0x8/KgAAABABn1V0Qr8BLvUSJ8WYo1WxAAAAEAGfV2pCvwE2zRvNMVbRyMEAAAAaQZtaSahBbJlMFEw7//6plgDC1OF/vq+5E7oAAAAQAZ95akK/AS7aITcZ9emq2QAAABhBm35J4QpSZTAhv/6nhAGC8dPtYVZwitgAAAAQQZ+cRTRML/8A3KrxvYIoeQAAAA8Bn7t0Qr8BLrQgMkuUm4EAAAAQAZ+9akK/ATbNG80xVtHIwAAAABlBm6BJqEFomUwU8O/+qZYAwtThf76vuRO6AAAAEAGf32pCvwEu2iE3GfXpqtkAAAAdQZvESeEKUmUwIb/+p4QELjM1Nm1495HAJr9MqygAAAAQQZ/iRTRML/8BZVXW8EBccQAAAA8BngF0Qr8BLrQgMkuUm4AAAAAQAZ4DakK/Ad8ff3xoavymgQAAABhBmgVJqEFomUwId//+qZYCJMRRkBbdAi8AAAASQZopSeEKUmUwId/+qZYAAJWBAAAADEGeR0U0TC//AACygQAAABABnmZ0Qr8BzEgGI7LsqMqAAAAADwGeaGpCvwHehe6dRuTxSQAAABNBmm1JqEFomUwId//+qZYAAJWBAAAADEGei0URLC//AACygAAAABABnqp0Qr8BzEgGI7LsqMqAAAAADwGerGpCvwHehe6dRuTxSQAAABNBmrFJqEFsmUwId//+qZYAAJWBAAAADEGez0UVLC//AACygQAAABABnu50Qr8BzEgGI7LsqMqAAAAADwGe8GpCvwHehe6dRuTxSQAAABNBmvVJqEFsmUwId//+qZYAAJWBAAAADEGfE0UVLC//AACygAAAABABnzJ0Qr8BzEgGI7LsqMqAAAAADwGfNGpCvwHehe6dRuTxSQAAABNBmzlJqEFsmUwId//+qZYAAJWAAAAADEGfV0UVLC//AACygQAAABABn3Z0Qr8BzEgGI7LsqMqBAAAADwGfeGpCvwHMSAXWerPRWwAAABNBm31JqEFsmUwId//+qZYAAJWBAAAADEGfm0UVLC//AACygAAAABABn7p0Qr8BzEgGI7LsqMqBAAAADwGfvGpCvwHehe6dRuTxSQAAABNBm6FJqEFsmUwId//+qZYAAJWAAAAADEGf30UVLC//AACygAAAABABn/50Qr8BzEgGI7LsqMqBAAAADwGf4GpCvwHehe6dRuTxSQAAABNBm+VJqEFsmUwId//+qZYAAJWBAAAADEGeA0UVLC//AACygAAAABABniJ0Qr8BzEgGI7LsqMqBAAAADwGeJGpCvwHehe6dRuTxSQAAABxBmilJqEFsmUwId//+qZYCAdmPzZKdEC3GBYypAAAAFUGeR0UVLC//AVsRuQBkxT6LK7QvGQAAABABnmZ0Qr8B0X8Bklv9bLKAAAAAEAGeaGpCvwE22I8lzPkk64AAAAAZQZptSahBbJlMCHf//qmWAfU+nuuPP5FjKwAAABVBnotFFSwv/wFbVdw4mHG76LK32pgAAAAPAZ6qdEK/ATZ2UKTbJVFbAAAAEAGerGpCvwHSH4F1/bh8wcEAAAATQZqxSahBbJlMCHf//qmWAACVgQAAABFBns9FFSwv/wFbiWx3DJjZgQAAABABnu50Qr8B0YFDPOYlNk3oAAAAEAGe8GpCvwHehe9ImNZlh4AAAAATQZr1SahBbJlMCHf//qmWAACVgQAAAAxBnxNFFSwv/wAAsoAAAAAQAZ8ydEK/AcxIBiOy7KjKgAAAAA8BnzRqQr8B3oXunUbk8UkAAAATQZs5SahBbJlMCHf//qmWAACVgAAAAAxBn1dFFSwv/wAAsoEAAAAQAZ92dEK/AcxIBiOy7KjKgQAAAA8Bn3hqQr8B3oXunUbk8UkAAAATQZt9SahBbJlMCHf//qmWAACVgQAAAAxBn5tFFSwv/wAAsoAAAAAQAZ+6dEK/AcxIBiOy7KjKgQAAAA8Bn7xqQr8B3oXunUbk8UkAAAASQZuhSahBbJlMCG///qeEAAEnAAAADEGf30UVLC//AACygAAAABABn/50Qr8BzEgGI7LsqMqBAAAADwGf4GpCvwHMSAXWerPRWwAAABJBm+VJqEFsmUwIZ//+nhAABH0AAAAMQZ4DRRUsL/8AALKAAAAADwGeInRCvwHfJA0QXOnhCwAAAA8BniRqQr8BzEgF1nqz0VsAAAAaQZopS6hCEFskRggoB/IB/YeAIV/+OEAAEXEAAAAjQZ5HRRUsL/8CAdzqS9szCrmA6Bq1qFwJQBlok8LfMpM0nDEAAAAPAZ5mdEK/Ad8kDRBc6eELAAAAIwGeaGpCvwKvY+1BxN2qw8zXiaBXZ0i0Brhm6/B7Rp3QO4sGAAAMGG1vb3YAAABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAAB+QAAEAAAEAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIAAAtCdHJhawAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAAAAAAAB+QAAAAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAEQAAABEAAAAAAAJGVkdHMAAAAcZWxzdAAAAAAAAAABAAAfkAAABAAAAQAAAAAKum1kaWEAAAAgbWRoZAAAAAAAAAAAAAAAAAAAMgAAAZQAVcQAAAAAAC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAAAAAAVmlkZW9IYW5kbGVyAAAACmVtaW5mAAAAFHZtaGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxkcmVmAAAAAAAAAAEAAAAMdXJsIAAAAAEAAAolc3RibAAAAJVzdHNkAAAAAAAAAAEAAACFYXZjMQAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAEQARAASAAAAEgAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABj//wAAAC9hdmNDAfQADf/hABdn9AANkZsoIhHQgAAAAwCAAAAZB4oUywEABWjr48RIAAAAGHN0dHMAAAAAAAAAAQAAAMoAAAIAAAAAFHN0c3MAAAAAAAAAAQAAAAEAAAXwY3R0cwAAAAAAAAC8AAAAAgAABAAAAAABAAAIAAAAAAIAAAIAAAAAAQAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAwAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAIAAAQAAAAAAQAACAAAAAACAAACAAAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAACAAAEAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAACAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAgAABAAAAAABAAAGAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAACAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAABxzdHNjAAAAAAAAAAEAAAABAAAAygAAAAEAAAM8c3RzegAAAAAAAAAAAAAAygAABd8AAAAYAAAAKwAAABUAAAAUAAAAHgAAAC0AAAAUAAAAFAAAABMAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAgAAAAFAAAABMAAAAUAAAAIAAAABwAAAAcAAAAGgAAABgAAAAUAAAAFAAAABYAAAAUAAAAFAAAABQAAAAWAAAAFAAAABQAAAAUAAAAHQAAABQAAAAdAAAAFQAAABcAAAAUAAAAFAAAAB4AAAAcAAAAHAAAABYAAAAUAAAAHgAAABUAAAAXAAAAFAAAABQAAAAeAAAAHAAAAB8AAAAWAAAAFAAAAB8AAAAVAAAAEwAAABQAAAAcAAAAFAAAAB0AAAAcAAAAHgAAABMAAAAfAAAAFgAAABQAAAAdAAAAGgAAACEAAAATAAAAHQAAABUAAAASAAAAHgAAABYAAAAQAAAAFAAAABQAAAAWAAAAEAAAABQAAAAUAAAAHwAAABQAAAATAAAAFAAAABcAAAATAAAAFgAAABMAAAAcAAAAHQAAACUAAAAUAAAAHAAAACIAAAAUAAAAIAAAABQAAAAcAAAAFAAAABMAAAAUAAAAHgAAABwAAAAWAAAAFAAAABYAAAAXAAAAFAAAABQAAAAeAAAAFAAAABwAAAAUAAAAEwAAABQAAAAdAAAAFAAAACEAAAAUAAAAEwAAABQAAAAcAAAAFgAAABAAAAAUAAAAEwAAABcAAAAQAAAAFAAAABMAAAAXAAAAEAAAABQAAAATAAAAFwAAABAAAAAUAAAAEwAAABcAAAAQAAAAFAAAABMAAAAXAAAAEAAAABQAAAATAAAAFwAAABAAAAAUAAAAEwAAABcAAAAQAAAAFAAAABMAAAAgAAAAGQAAABQAAAAUAAAAHQAAABkAAAATAAAAFAAAABcAAAAVAAAAFAAAABQAAAAXAAAAEAAAABQAAAATAAAAFwAAABAAAAAUAAAAEwAAABcAAAAQAAAAFAAAABMAAAAWAAAAEAAAABQAAAATAAAAFgAAABAAAAATAAAAEwAAAB4AAAAnAAAAEwAAACcAAAAUc3RjbwAAAAAAAAABAAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTcuODMuMTAw\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "metadata": {
        "id": "LhF0QnuEHK-G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
      ]
    },
    {
      "metadata": {
        "id": "U-u-yMmfHK-H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Flatten\n",
        "class DQN_CNN(DQN):\n",
        "    def __init__(self, *args,lr=0.1,**kwargs):\n",
        "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
        "        \n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(70, (2, 2), activation='relu', input_shape=(5, 5, self.n_state)))\n",
        "        model.add(Conv2D(70, (2, 2), activation='relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(1, 1)))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4, activation='softmax'))\n",
        "        \n",
        "        \n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qu5XNA07HK-L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "outputId": "3f390779-bc36-4561-9ee3-03a2262e824c"
      },
      "cell_type": "code",
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "train(agent,env,epochs_train,prefix='cnn_train')\n",
        "HTML(display_videos('cnn_train10.mp4'))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/020 | Loss 0.0407 | Win/lose count 2.5/3.0 (-0.5)\n",
            "Epoch 001/020 | Loss 0.0251 | Win/lose count 4.0/8.0 (-4.0)\n",
            "Epoch 002/020 | Loss 0.0433 | Win/lose count 3.0/4.0 (-1.0)\n",
            "Epoch 003/020 | Loss 0.0211 | Win/lose count 6.0/2.0 (4.0)\n",
            "Epoch 004/020 | Loss 0.0386 | Win/lose count 3.0/3.0 (0.0)\n",
            "Epoch 005/020 | Loss 0.0134 | Win/lose count 1.5/4.0 (-2.5)\n",
            "Epoch 006/020 | Loss 0.0479 | Win/lose count 1.5/1.0 (0.5)\n",
            "Epoch 007/020 | Loss 0.0245 | Win/lose count 4.0/4.0 (0.0)\n",
            "Epoch 008/020 | Loss 0.0272 | Win/lose count 0.5/1.0 (-0.5)\n",
            "Epoch 009/020 | Loss 0.0206 | Win/lose count 3.0/3.0 (0.0)\n",
            "Epoch 010/020 | Loss 0.0215 | Win/lose count 2.0/1.0 (1.0)\n",
            "Epoch 011/020 | Loss 0.0148 | Win/lose count 4.5/4.0 (0.5)\n",
            "Epoch 012/020 | Loss 0.0142 | Win/lose count 1.5/1.0 (0.5)\n",
            "Epoch 013/020 | Loss 0.0241 | Win/lose count 1.5/3.0 (-1.5)\n",
            "Epoch 014/020 | Loss 0.0171 | Win/lose count 1.5/3.0 (-1.5)\n",
            "Epoch 015/020 | Loss 0.0270 | Win/lose count 0.5/3.0 (-2.5)\n",
            "Epoch 016/020 | Loss 0.0289 | Win/lose count 2.0/5.0 (-3.0)\n",
            "Epoch 017/020 | Loss 0.0229 | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 018/020 | Loss 0.0262 | Win/lose count 2.5/2.0 (0.5)\n",
            "Epoch 019/020 | Loss 0.0194 | Win/lose count 1.5/1.0 (0.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "metadata": {
        "id": "8fXRQwDkHK-V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
      ]
    },
    {
      "metadata": {
        "id": "SKoUoS4IHK-W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "af8852a2-9df9-4df6-91bc-6edc2d70fb60"
      },
      "cell_type": "code",
      "source": [
        "temperature=[0.1,0.5,0.9]\n",
        "for i in temperature:\n",
        "    env = Environment(grid_size=size, max_time=T,temperature=i)\n",
        "    agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "    agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
        "\n",
        "    agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "    agent_cnn.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
        "    print('Test of the CNN')\n",
        "    test(agent_cnn,env,5,prefix='cnn_test')\n",
        "    print('Test of the FC')\n",
        "    test(agent_fc,env,5,prefix='fc_test')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test of the CNN\n",
            "Win/lose count 2.5/0. Average score (2.5)\n",
            "Win/lose count 2.0/0. Average score (2.25)\n",
            "Win/lose count 0.5/0. Average score (1.6666666666666667)\n",
            "Win/lose count 0/0. Average score (1.25)\n",
            "Win/lose count 0/0. Average score (1.0)\n",
            "Final score: 1.0\n",
            "Test of the FC\n",
            "Win/lose count 0/0. Average score (0.0)\n",
            "Win/lose count 0/0. Average score (0.0)\n",
            "Win/lose count 0/3.0. Average score (-1.0)\n",
            "Win/lose count 0.5/0. Average score (-0.625)\n",
            "Win/lose count 0/0. Average score (-0.5)\n",
            "Final score: -0.5\n",
            "Test of the CNN\n",
            "Win/lose count 5.5/0. Average score (5.5)\n",
            "Win/lose count 1.0/0. Average score (3.25)\n",
            "Win/lose count 0.5/0. Average score (2.3333333333333335)\n",
            "Win/lose count 4.5/0. Average score (2.875)\n",
            "Win/lose count 1.0/0. Average score (2.5)\n",
            "Final score: 2.5\n",
            "Test of the FC\n",
            "Win/lose count 0.5/0. Average score (0.5)\n",
            "Win/lose count 2.0/3.0. Average score (-0.25)\n",
            "Win/lose count 0.5/0. Average score (0.0)\n",
            "Win/lose count 1.5/1.0. Average score (0.125)\n",
            "Win/lose count 1.0/3.0. Average score (-0.3)\n",
            "Final score: -0.3\n",
            "Test of the CNN\n",
            "Win/lose count 5.0/0. Average score (5.0)\n",
            "Win/lose count 5.0/0. Average score (5.0)\n",
            "Win/lose count 1.5/0. Average score (3.8333333333333335)\n",
            "Win/lose count 7.5/0. Average score (4.75)\n",
            "Win/lose count 2.5/0. Average score (4.3)\n",
            "Final score: 4.3\n",
            "Test of the FC\n",
            "Win/lose count 2.0/0. Average score (2.0)\n",
            "Win/lose count 1.5/1.0. Average score (1.25)\n",
            "Win/lose count 3.5/1.0. Average score (1.6666666666666667)\n",
            "Win/lose count 3.0/1.0. Average score (1.75)\n",
            "Win/lose count 0.5/0. Average score (1.5)\n",
            "Final score: 1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3kYNI4izHK-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "c15fc66b-f057-4758-9677-7fe19b7b11f3"
      },
      "cell_type": "code",
      "source": [
        "HTML(display_videos('cnn_test10.mp4'))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "metadata": {
        "id": "uM_nH825HK-h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "604c379b-1ddc-454f-9e24-4853f96eeaf7"
      },
      "cell_type": "code",
      "source": [
        "HTML(display_videos('fc_test10.mp4'))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAFc1tZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiByMjg1NCBlOWE1OTAzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MToweDExMSBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MCBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD00IHRocmVhZHM9MyBsb29rYWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAANLZYiEADP//vaG+BTYUyP+T7/8I/+5H7cfWfrixkIJvrVeQ9GAMl8a/5lGYaXpyc8t7R+vTNAEZz6HlLJIofgUkwDfMsjnE4osBFihUnQqRrKjcG2ViDAXGBNNc2MzP+J+mwcPUfak6eKwOkkj79/q2Hj9WMfSxrqjIn1bOxgXFPitWkJqTE6j3BDktsl5shfvnnB9bkVtFcpUTBZ8caKdxhnyEJZh7gvlSFTx7RTKOmbp/zttZcmwjwlXfRVZ3qwiwIJ5/P4/eeVayZBiaJf6KhAjjRf8ySjRXKsmjkalhJg7nsCRKcObreI0jKl6wCbCQ5jqRZyOJlA1IWWMK8TqEcm4Q/zSuGQkLvwWWFY6l8pj+FIrU6amWpicgIXAlGiNxOLizmIF0d3s++esNMP8fFruUuIkRXT6XAAFqmjxM/eoQaE1juzAUqgIc9yibWmPUAi0m6+4ABLsuBWyzIHSJ5YxQEQOIVKnz1foMkow+z6amARWndIpsAhWsqVh1DvYBPiQ/iUECqJdOpHpQ29mVN4f5jMPGummbwfgnZwmNbKVKBMWz8Tl3mks6udczxMAMh57NdeZlnq/OJ7ei/oRsYrTAFGRcBZlQk+7dG10q1CNZ1sQLGWoCP95w9tZFq9mmM1BmH9/2lXqjpzIgmR5gpNj360QgnRe5ixwpZtLR+/XCKI78uscy2H8GY6exsBz8FrIIXvAKz8ziYAd0aAdyto2WNyMVtD5EZbjRCbQ3LAy/CoUrsLnMjfGKtkGykXO1ZnNUZu4I6SKRhc5crektuky+x0bjWmdE7eTlWa2AGIfM4uUta/vtuOEp0AQc8P30P1/616/SfVn2StPuxJ/cov9K8gh9G/LG5Bwn9wR4Hez2gk8O/oKAUqmAdU8O/4CWkoP7vXoyjfHDK7hH2JnW1XJ+Er9pEyUkahAZJB/CYWEHmhZ0w287mG6uUE6p+uGcVsKgGE7nxX0bhuWiu8EnW0lyega3dZ0sXp76OtqVDdyFc6ttLTYKx/Ou0aWy/1wD5HiTcYUUAvA/5npAkBBI2+TiAPwzFyimcYFpK7HIFahtDrvAuUPhiumYOJGCTgHNFcLnTBBi13ruaLjeAVQAaM3GZAfFWgAABDRAAAAE0GaIWxDP/6eEAGH4LYLJxgVM5UAAAAYQZpCPCGTKYQ3//6nhAA/vsH+E4LdCVlBAAAAHEGaZEnhDyZTBTw3//6nhAAqPup+1Xm1RGRkChwAAAAPAZ6DakK/ACGyuRV4AoATAAAAGUGahUnhDyZTAhv//qeEABFvjp9RxoSHYEEAAAAdQZqnSeEPJlMFETw3//6nhAALZ7qfuZGFsxQjnS0AAAAQAZ7GakK/AAksroqs4/A5YQAAABlBmshJ4Q8mUwId//6plgADk/Cj67EG4rSwAAAAFkGa7EnhDyZTAh3//qmWAAGC+FH3d2AAAAAOQZ8KRRE8L/8AAcT99eEAAAAQAZ8pdEK/AAOsob2XVfxiQAAAABABnytqQr8AA6yhvYrR922AAAAAE0GbMEmoQWiZTAh3//6plgAAlYEAAAAMQZ9ORREsL/8AALKBAAAAEAGfbXRCvwADrKG9l1X8YkEAAAAQAZ9vakK/AAOsob2K0fdtgAAAABNBm3RJqEFsmUwId//+qZYAAJWAAAAADEGfkkUVLC//AACygQAAABABn7F0Qr8AA6yhvZdV/GJAAAAAEAGfs2pCvwADrKG9itH3bYAAAAATQZu4SahBbJlMCHf//qmWAACVgQAAAAxBn9ZFFSwv/wAAsoAAAAAQAZ/1dEK/AAOsob2XVfxiQQAAABABn/dqQr8AA6yhvYrR922BAAAAE0Gb/EmoQWyZTAh3//6plgAAlYAAAAAMQZ4aRRUsL/8AALKBAAAAEAGeOXRCvwADrKG9l1X8YkAAAAAQAZ47akK/AAOsob2K0fdtgQAAABNBmiBJqEFsmUwId//+qZYAAJWBAAAADEGeXkUVLC//AACygAAAABABnn10Qr8AA6yhvZdV/GJAAAAAEAGef2pCvwADrKG9itH3bYEAAAATQZpkSahBbJlMCHf//qmWAACVgAAAAAxBnoJFFSwv/wAAsoEAAAAQAZ6hdEK/AAOsob2XVfxiQAAAABABnqNqQr8AA6yhvYrR922BAAAAE0GaqEmoQWyZTAh3//6plgAAlYEAAAAMQZ7GRRUsL/8AALKBAAAAEAGe5XRCvwADrKG9l1X8YkEAAAAQAZ7nakK/AAOsob2K0fdtgAAAABNBmuxJqEFsmUwId//+qZYAAJWAAAAADEGfCkUVLC//AACygQAAABABnyl0Qr8AA6yhvZdV/GJAAAAAEAGfK2pCvwADrKG9itH3bYAAAAATQZswSahBbJlMCHf//qmWAACVgQAAAAxBn05FFSwv/wAAsoEAAAAQAZ9tdEK/AAOsob2XVfxiQQAAABABn29qQr8AA6yhvYrR922AAAAAE0GbdEmoQWyZTAh3//6plgAAlYAAAAAMQZ+SRRUsL/8AALKBAAAAEAGfsXRCvwADrKG9l1X8YkAAAAAQAZ+zakK/AAOsob2K0fdtgAAAABNBm7hJqEFsmUwId//+qZYAAJWBAAAADEGf1kUVLC//AACygAAAABABn/V0Qr8AA6yhvZdV/GJBAAAAEAGf92pCvwADrKG9itH3bYEAAAATQZv8SahBbJlMCHf//qmWAACVgAAAAAxBnhpFFSwv/wAAsoEAAAAQAZ45dEK/AAOsob2XVfxiQAAAABABnjtqQr8AA6yhvYrR922BAAAAE0GaIEmoQWyZTAh3//6plgAAlYEAAAAMQZ5eRRUsL/8AALKAAAAAEAGefXRCvwADrKG9l1X8YkAAAAAQAZ5/akK/AAOsob2K0fdtgQAAABNBmmRJqEFsmUwId//+qZYAAJWAAAAADEGegkUVLC//AACygQAAABABnqF0Qr8AA6yhvZdV/GJAAAAAEAGeo2pCvwADrKG9itH3bYEAAAATQZqoSahBbJlMCHf//qmWAACVgQAAAAxBnsZFFSwv/wAAsoEAAAAQAZ7ldEK/AAOsob2XVfxiQQAAABABnudqQr8AA6yhvYrR922AAAAAE0Ga7EmoQWyZTAh3//6plgAAlYAAAAAMQZ8KRRUsL/8AALKBAAAAEAGfKXRCvwADrKG9l1X8YkAAAAAQAZ8rakK/AAOsob2K0fdtgAAAABNBmzBJqEFsmUwId//+qZYAAJWBAAAADEGfTkUVLC//AACygQAAABABn210Qr8AA6yhvZdV/GJBAAAAEAGfb2pCvwADrKG9itH3bYAAAAATQZt0SahBbJlMCHf//qmWAACVgAAAAAxBn5JFFSwv/wAAsoEAAAAQAZ+xdEK/AAOsob2XVfxiQAAAABABn7NqQr8AA6yhvYrR922AAAAAE0GbuEmoQWyZTAh3//6plgAAlYEAAAAMQZ/WRRUsL/8AALKAAAAAEAGf9XRCvwADrKG9l1X8YkEAAAAQAZ/3akK/AAOsob2K0fdtgQAAABNBm/xJqEFsmUwId//+qZYAAJWAAAAADEGeGkUVLC//AACygQAAABABnjl0Qr8AA6yhvZdV/GJAAAAAEAGeO2pCvwADrKG9itH3bYEAAAATQZogSahBbJlMCHf//qmWAACVgQAAAAxBnl5FFSwv/wAAsoAAAAAQAZ59dEK/AAOsob2XVfxiQAAAABABnn9qQr8AA6yhvYrR922BAAAAE0GaZEmoQWyZTAh3//6plgAAlYAAAAAMQZ6CRRUsL/8AALKBAAAAEAGeoXRCvwADrKG9l1X8YkAAAAAQAZ6jakK/AAOsob2K0fdtgQAAABNBmqhJqEFsmUwId//+qZYAAJWBAAAADEGexkUVLC//AACygQAAABABnuV0Qr8AA6yhvZdV/GJBAAAAEAGe52pCvwADrKG9itH3bYAAAAATQZrsSahBbJlMCHf//qmWAACVgAAAAAxBnwpFFSwv/wAAsoEAAAAQAZ8pdEK/AAOsob2XVfxiQAAAABABnytqQr8AA6yhvYrR922AAAAAE0GbMEmoQWyZTAh3//6plgAAlYEAAAAMQZ9ORRUsL/8AALKBAAAAEAGfbXRCvwADrKG9l1X8YkEAAAAQAZ9vakK/AAOsob2K0fdtgAAAABNBm3RJqEFsmUwId//+qZYAAJWAAAAADEGfkkUVLC//AACygQAAABABn7F0Qr8AA6yhvZdV/GJAAAAAEAGfs2pCvwADrKG9itH3bYAAAAATQZu4SahBbJlMCHf//qmWAACVgQAAAAxBn9ZFFSwv/wAAsoAAAAAQAZ/1dEK/AAOsob2XVfxiQQAAABABn/dqQr8AA6yhvYrR922BAAAAE0Gb/EmoQWyZTAh3//6plgAAlYAAAAAMQZ4aRRUsL/8AALKBAAAAEAGeOXRCvwADrKG9l1X8YkAAAAAQAZ47akK/AAOsob2K0fdtgQAAABNBmiBJqEFsmUwId//+qZYAAJWBAAAADEGeXkUVLC//AACygAAAABABnn10Qr8AA6yhvZdV/GJAAAAAEAGef2pCvwADrKG9itH3bYEAAAATQZpkSahBbJlMCHf//qmWAACVgAAAAAxBnoJFFSwv/wAAsoEAAAAQAZ6hdEK/AAOsob2XVfxiQAAAABABnqNqQr8AA6yhvYrR922BAAAAE0GaqEmoQWyZTAh3//6plgAAlYEAAAAMQZ7GRRUsL/8AALKBAAAAEAGe5XRCvwADrKG9l1X8YkEAAAAQAZ7nakK/AAOsob2K0fdtgAAAABNBmuxJqEFsmUwId//+qZYAAJWAAAAADEGfCkUVLC//AACygQAAABABnyl0Qr8AA6yhvZdV/GJAAAAAEAGfK2pCvwADrKG9itH3bYAAAAATQZswSahBbJlMCHf//qmWAACVgQAAAAxBn05FFSwv/wAAsoEAAAAQAZ9tdEK/AAOsob2XVfxiQQAAABABn29qQr8AA6yhvYrR922AAAAAE0GbdEmoQWyZTAh3//6plgAAlYAAAAAMQZ+SRRUsL/8AALKBAAAAEAGfsXRCvwADrKG9l1X8YkAAAAAQAZ+zakK/AAOsob2K0fdtgAAAABNBm7hJqEFsmUwId//+qZYAAJWBAAAADEGf1kUVLC//AACygAAAABABn/V0Qr8AA6yhvZdV/GJBAAAAEAGf92pCvwADrKG9itH3bYEAAAATQZv8SahBbJlMCHf//qmWAACVgAAAAAxBnhpFFSwv/wAAsoEAAAAQAZ45dEK/AAOsob2XVfxiQAAAABABnjtqQr8AA6yhvYrR922BAAAAE0GaIEmoQWyZTAh3//6plgAAlYEAAAAMQZ5eRRUsL/8AALKAAAAAEAGefXRCvwADrKG9l1X8YkAAAAAQAZ5/akK/AAOsob2K0fdtgQAAABNBmmRJqEFsmUwId//+qZYAAJWAAAAADEGegkUVLC//AACygQAAABABnqF0Qr8AA6yhvZdV/GJAAAAAEAGeo2pCvwADrKG9itH3bYEAAAATQZqoSahBbJlMCHf//qmWAACVgQAAAAxBnsZFFSwv/wAAsoEAAAAQAZ7ldEK/AAOsob2XVfxiQQAAABABnudqQr8AA6yhvYrR922AAAAAE0Ga7EmoQWyZTAh3//6plgAAlYAAAAAMQZ8KRRUsL/8AALKBAAAAEAGfKXRCvwADrKG9l1X8YkAAAAAQAZ8rakK/AAOsob2K0fdtgAAAABNBmzBJqEFsmUwId//+qZYAAJWBAAAADEGfTkUVLC//AACygQAAABABn210Qr8AA6yhvZdV/GJBAAAAEAGfb2pCvwADrKG9itH3bYAAAAATQZt0SahBbJlMCHf//qmWAACVgAAAAAxBn5JFFSwv/wAAsoEAAAAQAZ+xdEK/AAOsob2XVfxiQAAAABABn7NqQr8AA6yhvYrR922AAAAAE0GbuEmoQWyZTAh3//6plgAAlYEAAAAMQZ/WRRUsL/8AALKAAAAAEAGf9XRCvwADrKG9l1X8YkEAAAAQAZ/3akK/AAOsob2K0fdtgQAAABNBm/xJqEFsmUwId//+qZYAAJWAAAAADEGeGkUVLC//AACygQAAABABnjl0Qr8AA6yhvZdV/GJAAAAAEAGeO2pCvwADrKG9itH3bYEAAAASQZogSahBbJlMCG///qeEAAEnAAAADEGeXkUVLC//AACygAAAABABnn10Qr8AA6yhvZdV/GJAAAAAEAGef2pCvwADrKG9itH3bYEAAAASQZpkSahBbJlMCG///qeEAAEnAAAADEGegkUVLC//AACygQAAABABnqF0Qr8AA6yhvZdV/GJAAAAAEAGeo2pCvwADrKG9itH3bYEAAAASQZqoSahBbJlMCF///oywAASNAAAADEGexkUVLC//AACygQAAABABnuV0Qr8AA6yhvZdV/GJBAAAAEAGe52pCvwADrKG9itH3bYAAAAAaQZrpS6hCEFskRggoB/IB/YeAIV/+OEAAEXAAAAx4bW9vdgAAAGxtdmhkAAAAAAAAAAAAAAAAAAAD6AAAH5AAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAAC6J0cmFrAAAAXHRraGQAAAADAAAAAAAAAAAAAAABAAAAAAAAH5AAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAARAAAAEQAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEAAB+QAAAEAAABAAAAAAsabWRpYQAAACBtZGhkAAAAAAAAAAAAAAAAAAAyAAABlABVxAAAAAAALWhkbHIAAAAAAAAAAHZpZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRsZXIAAAAKxW1pbmYAAAAUdm1oZAAAAAEAAAAAAAAAAAAAACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAACoVzdGJsAAAAlXN0c2QAAAAAAAAAAQAAAIVhdmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAARABEABIAAAASAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAAL2F2Y0MB9AAN/+EAF2f0AA2RmygiEdCAAAADAIAAABkHihTLAQAFaOvjxEgAAAAYc3R0cwAAAAAAAAABAAAAygAAAgAAAAAUc3RzcwAAAAAAAAABAAAAAQAABlBjdHRzAAAAAAAAAMgAAAADAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAADKAAAAAQAAAzxzdHN6AAAAAAAAAAAAAADKAAAGAAAAABcAAAAcAAAAIAAAABMAAAAdAAAAIQAAABQAAAAdAAAAGgAAABIAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAXAAAAEAAAABQAAAAUAAAAFgAAABAAAAAUAAAAFAAAABYAAAAQAAAAFAAAABQAAAAWAAAAEAAAABQAAAAUAAAAHgAAABRzdGNvAAAAAAAAAAEAAAAwAAAAYnVkdGEAAABabWV0YQAAAAAAAAAhaGRscgAAAAAAAAAAbWRpcmFwcGwAAAAAAAAAAAAAAAAtaWxzdAAAACWpdG9vAAAAHWRhdGEAAAABAAAAAExhdmY1Ny44My4xMDA=\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "metadata": {
        "id": "1dlHda2jHK-n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**CNN and FN**: from the above results, we can see that CNN performs better than FC. But the videos show that the agent just moves in a certain area and it seldom explores new area. The result is that the agent cannot earn more rewards from other boards. We can try to improve the exploration rate to improve the performance.\n",
        "\n",
        "**Weather**: I simply try three temperatures. The results indicate a positive relationship between scores and weather. This is because by inceasing the temperature, we also increase the probability of cheese cells and decrease the probability of poisonious cells."
      ]
    },
    {
      "metadata": {
        "id": "3XtvafElHK-v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
        "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
        "2. Append via the environment a new state that describes if a cell has been visited or not\n",
        "\n",
        "***\n",
        "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "mLA0mZel2RgG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_explore(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    \n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            \n",
        "            # Epsilon-greedy \n",
        "            agent.set_epsilon(np.float(agent.get_epsilon())*0.995)\n",
        "            \n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action, train=True)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose - reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "            \n",
        "        # Save as a mp4       \n",
        "        env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
        "        \n",
        "    print('Final score: '+str(score/epoch))\n",
        "        \n",
        "class EnvironmentExploring(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size + 4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "        \n",
        "        self.board = np.zeros([grid_size,grid_size])\n",
        "        self.position = np.zeros([grid_size,grid_size])\n",
        "        self.malus_position = np.zeros([grid_size,grid_size])\n",
        "        \n",
        "        # coordinate of the rat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "        \n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "        \n",
        "    def get_t(self):\n",
        "        return self.t\n",
        "    \n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "             \n",
        "        \n",
        "    def act(self, action, train=True):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[:, -2:] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        \n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "        \n",
        "        self.t = self.t + 1\n",
        "        \n",
        "        \n",
        "        # You will have to change n_state to 3 because you will use one more layer!\n",
        "        reward = 0\n",
        "        if train:\n",
        "            reward -= self.malus_position[self.x, self.y]\n",
        "\n",
        "        self.malus_position[self.x, self.y] = 0.01\n",
        "        reward = reward + self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "\n",
        "        # 3 \"feature\" states instead of 2\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        \n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "        \n",
        "        return state, reward, game_over\n",
        "    \n",
        "    \n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[:, -2:] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "       \n",
        "        self.malus_position[self.x, self.y] = 0\n",
        "\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        \n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "riS4E0DCHK-y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "outputId": "1aeddcfb-2dcf-4ff4-e7e5-4bc69c3d0093"
      },
      "cell_type": "code",
      "source": [
        "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32,n_state=3)\n",
        "train_explore(agent, env, 5, prefix='cnn_train_explore')\n",
        "HTML(display_videos('cnn_train_explore10.mp4'))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/005 | Loss 0.0093 | Win/lose count 5.0/6.7599999999999625 (-1.7599999999999625)\n",
            "Epoch 001/005 | Loss 0.0041 | Win/lose count 0.5/2.929999999999981 (-2.429999999999981)\n",
            "Epoch 002/005 | Loss 0.0162 | Win/lose count 2.0/3.8899999999999597 (-1.8899999999999597)\n",
            "Epoch 003/005 | Loss 0.0340 | Win/lose count 0/4.009999999999958 (-4.009999999999958)\n",
            "Epoch 004/005 | Loss 0.0279 | Win/lose count 0/1.9900000000000015 (-1.9900000000000015)\n",
            "Final score: -2.415999999999973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "metadata": {
        "id": "vOL3cjjBHK-3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "f5ef4027-516f-4eff-efc3-df68edfd5745"
      },
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "test(agent,env,5,prefix='cnn_test_explore')\n",
        "HTML(display_videos('cnn_test_explore10.mp4'))"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 1.99/2.9099999999999815. Average score (-0.9199999999999815)\n",
            "Win/lose count 0/2.0000000000000013. Average score (-1.4599999999999915)\n",
            "Win/lose count 1.96/5.969999999999959. Average score (-2.3099999999999805)\n",
            "Win/lose count 0/3.0099999999999794. Average score (-2.4849999999999803)\n",
            "Win/lose count 0.99/3.989999999999958. Average score (-2.5879999999999757)\n",
            "Final score: -2.5879999999999757\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "metadata": {
        "id": "a4PHdopNHK--",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
      ]
    },
    {
      "metadata": {
        "id": "Gu8F4i7yHK-_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "vkk44CE7HK_B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***"
      ]
    }
  ]
}